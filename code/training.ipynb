{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsperaDesu/LoL-AI-Draft-Picker/blob/main/code/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a6J137mhWMX",
        "outputId": "e74c2d61-c1ee-4315-de2d-4239b3ef5f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, python-dotenv, outcome, webdriver-manager, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 python-dotenv-1.1.1 selenium-4.34.2 trio-0.30.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "%pip install requests beautifulsoup4 selenium pandas webdriver-manager"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AsperaDesu/LoL-AI-Draft-Picker.git\n",
        "%cd LoL-AI-Draft-Picker/code"
      ],
      "metadata": {
        "id": "7ZP8zkb6xMy3",
        "outputId": "be930118-cac4-4588-a010-9905572e473b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LoL-AI-Draft-Picker'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 78 (delta 33), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (78/78), 6.20 MiB | 9.38 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "/content/LoL-AI-Draft-Picker/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load utils.py\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "\n",
        "def get_champion_classes():\n",
        "    url = \"https://leagueoflegends.fandom.com/wiki/List_of_champions\"\n",
        "    resp = requests.get(url, headers=HEADERS)\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "    table = soup.select_one(\"table.article-table\")\n",
        "    classes = {}\n",
        "    for row in table.select(\"tr\")[1:]:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) < 2:\n",
        "            continue\n",
        "        name = cols[0].get(\"data-sort-value\")\n",
        "        raw = cols[1].get(\"data-sort-value\")\n",
        "        if name and raw:\n",
        "            classes[name] = [c.strip() for c in raw.split(\",\")]\n",
        "    return classes\n",
        "\n",
        "def get_champion_scores(patch='14.5'):\n",
        "    url = f'https://www.metasrc.com/lol/{patch}/stats?ranks=grandmaster,challenger'\n",
        "\n",
        "    temp_profile = tempfile.mkdtemp()\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument(f\"--user-data-dir={temp_profile}\")  # Prevent profile collision\n",
        "    options.add_argument(\"--disable-gpu\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    print(f\"Opening MetaSRC patch {patch}...\")\n",
        "    driver.get(url)\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    driver.quit()\n",
        "\n",
        "    table = soup.find('table')\n",
        "    if not table:\n",
        "        raise Exception(\"Stats table not found.\")\n",
        "\n",
        "    data = []\n",
        "    rows = table.find_all('tr')[1:]  # Skip header\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "        if len(cols) < 3:\n",
        "            continue\n",
        "\n",
        "        champ = cols[0].find(\"span\").text.strip()\n",
        "        role = cols[1].get_text(strip=True).lower()\n",
        "        score = cols[3].get_text(strip=True)\n",
        "        role = role if role != 'adc' else 'bot'\n",
        "        data.append({\n",
        "            \"champion\": champ,\n",
        "            \"role\": role,\n",
        "            \"score\": score\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def load_or_fetch_scores(patch='14.5'):\n",
        "    file_path = f\"champion_scores_{patch}.csv\"\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"Loading cached scores for patch {patch}\")\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(\"-Loading completed\")\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"Fetching scores for patch {patch} from MetaSRC\")\n",
        "        df = get_champion_scores(patch)\n",
        "        df.to_csv(file_path, index=False)\n",
        "        print(\"-Fetching completed\")\n",
        "        return df\n",
        "\n",
        "def tokenize_draft(match, tokenizer):\n",
        "    match[\"blue_picks\"] = tokenizer.encode(match[\"blue_picks\"])\n",
        "    match[\"red_picks\"] = tokenizer.encode(match[\"red_picks\"])\n",
        "    match[\"blue_bans\"] = tokenizer.encode(match[\"blue_bans\"])\n",
        "    match[\"red_bans\"] = tokenizer.encode(match[\"red_bans\"])\n",
        "    return match\n",
        "\n",
        "def tokenize_roles(match, tokenizer):\n",
        "    match[\"blue_roles\"] = tokenizer.encodeRole(match['roles']['blue'])\n",
        "    match[\"red_roles\"] = tokenizer.encodeRole(match['roles']['red'])\n",
        "    return match\n",
        "\n",
        "def drop_raw_picks_bans(match):\n",
        "    for key in [\"match\", \"blue_team\", \"red_team\", \"winner\", \"roles\"]:\n",
        "        match.pop(key, None)\n",
        "    return match"
      ],
      "metadata": {
        "id": "11G6ArnSl6dw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "from pathlib import Path\n",
        "from utils import *\n",
        "\n",
        "ROLES = ['Start', 'Banned', 'Jungle', 'Mid', 'Top', 'Bot', 'Support']\n",
        "START_TOKEN = '<start>'\n",
        "\n",
        "current_path = Path().resolve()\n",
        "\n",
        "# Walk up until we find a 'data' folder (as a sibling)\n",
        "while not (current_path / 'data').exists() and current_path != current_path.parent:\n",
        "    current_path = current_path.parent\n",
        "\n",
        "data_dir = current_path / 'data'\n",
        "\n",
        "if data_dir.exists():\n",
        "    if Path.cwd() != data_dir:\n",
        "        os.chdir(data_dir)\n",
        "        print(f\"Changed working directory to: {data_dir}\")\n",
        "    else:\n",
        "        print(f\"Already in data directory: {data_dir}\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Could not find 'data' directory.\")\n",
        "\n",
        "# Getting the draft data\n",
        "with open('lck_spring_raw.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "for match in data:\n",
        "  if match['winner'] == match['blue_team']:\n",
        "      match['winner_token'] = 0\n",
        "  else:\n",
        "      match['winner_token'] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB-hBFw9jFyx",
        "outputId": "183dd163-af0c-45ef-8c28-0925727be20e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed working directory to: /content/LoL-AI-Draft-Picker/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ChampionTokenizer:\n",
        "    def __init__(self, champ_names):\n",
        "        self.champ_names = sorted(set(champ_names))\n",
        "        self.token_to_id = {name: idx for idx, name in enumerate(self.champ_names)}\n",
        "        self.id_to_token = {idx: name for name, idx in self.token_to_id.items()}\n",
        "        self.role_to_id = {role: ix for ix, role in enumerate(ROLES)}\n",
        "        self.id_to_role = {ix: role for role, ix in self.role_to_id.items()}\n",
        "\n",
        "    def encode(self, names):\n",
        "        \"\"\"Convert a list of champion names into token IDs.\"\"\"\n",
        "        return torch.tensor([self.token_to_id[name] for name in names], dtype=torch.long)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        \"\"\"Convert a list of token IDs into champion names.\"\"\"\n",
        "        return [self.id_to_token[id.item()] for id in ids]\n",
        "\n",
        "    def encodeRole(self, roles):\n",
        "        return torch.tensor([self.role_to_id[role] for role in roles])\n",
        "\n",
        "    def decodeRole(self, tokens):\n",
        "        return [self.id_to_role[token] for token in tokens]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.champ_names)\n",
        "\n",
        "\n",
        "class ClassTokenizer:\n",
        "    def __init__(self, classes):\n",
        "        self.encoder = {class_: ix for ix, class_ in enumerate(classes)}\n",
        "        self.decoder = {ix: class_ for class_, ix in self.encoder.items()}\n",
        "\n",
        "    def encode(self, classes):\n",
        "        return torch.tensor([self.encoder[class_] for class_ in classes])\n",
        "\n",
        "    def decode(self, class_tokens):\n",
        "        return [self.decoder[token.item()] for token in class_tokens]"
      ],
      "metadata": {
        "id": "POhY8I6kmRHp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting champion scores from MetaSRC across patches\n",
        "patches = set([match['patch'] for match in data])\n",
        "champion_scores = {patch : load_or_fetch_scores(patch) for patch in patches}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC-xfgqTlsbg",
        "outputId": "382ce97f-f934-40ae-fe37-5b870c8132f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching scores for patch 14.2 from MetaSRC\n",
            "Opening MetaSRC patch 14.2...\n",
            "-Fetching completed\n",
            "Fetching scores for patch 14.1B from MetaSRC\n",
            "Opening MetaSRC patch 14.1B...\n",
            "-Fetching completed\n",
            "Loading cached scores for patch 14.5\n",
            "-Loading completed\n",
            "Fetching scores for patch 14.3 from MetaSRC\n",
            "Opening MetaSRC patch 14.3...\n",
            "-Fetching completed\n",
            "Fetching scores for patch 14.4 from MetaSRC\n",
            "Opening MetaSRC patch 14.4...\n",
            "-Fetching completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "winner_vocab_size = 3\n",
        "\n",
        "# Getting the set of available champion names\n",
        "latest_patch = max(patches)\n",
        "champion_names = champion_scores[latest_patch]['champion'].tolist()\n",
        "champion_names.insert(0, START_TOKEN)\n",
        "champion_names = set(champion_names)\n",
        "\n",
        "# Initializing champion tokenizer class\n",
        "champion_vocab_size = len(champion_names)\n",
        "champ_tokenizer = ChampionTokenizer(champion_names)"
      ],
      "metadata": {
        "id": "vPhiLE_im8ry"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting champs classes\n",
        "champ_classes = get_champion_classes()\n",
        "champ_classes[START_TOKEN] = ['START']\n",
        "\n",
        "# Addressing the different naming of \"Nunu & Willump\"\n",
        "champ_classes['Nunu'] = champ_classes.pop('Nunu & Willump')\n",
        "\n",
        "available_classes = set([class_ for classes in champ_classes.values() for class_ in classes])\n",
        "class_tokenizer = ClassTokenizer(available_classes)"
      ],
      "metadata": {
        "id": "xVO2B8ZZms3C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "# Tokenizing and cleaning matches\n",
        "matches = [tokenize_roles(tokenize_draft(match, champ_tokenizer), champ_tokenizer) for match in copy.deepcopy(data)]\n",
        "matches = [drop_raw_picks_bans(match) for match in matches]\n",
        "matches[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvXLLGoIpINj",
        "outputId": "aa08b3cb-7614-4cea-e424-19f42884b715"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'patch': '14.5',\n",
              "  'blue_bans': tensor([ 69, 109,  94,  65, 106]),\n",
              "  'red_bans': tensor([113,  56, 142,  74,  27]),\n",
              "  'blue_picks': tensor([147,   2,   1,  19,  10]),\n",
              "  'red_picks': tensor([ 73, 130,  85,  54, 102]),\n",
              "  'winner_token': 1,\n",
              "  'blue_roles': tensor([2, 3, 4, 5, 6]),\n",
              "  'red_roles': tensor([5, 3, 6, 4, 2])},\n",
              " {'patch': '14.5',\n",
              "  'blue_bans': tensor([112, 142, 148,   1, 147]),\n",
              "  'red_bans': tensor([ 69, 113,  10,   2,  94]),\n",
              "  'blue_picks': tensor([ 56, 109, 156, 128,  87]),\n",
              "  'red_picks': tensor([ 88, 130,  27,  50,  54]),\n",
              "  'winner_token': 1,\n",
              "  'blue_roles': tensor([5, 4, 2, 3, 6]),\n",
              "  'red_roles': tensor([6, 3, 5, 2, 4])},\n",
              " {'patch': '14.5',\n",
              "  'blue_bans': tensor([  2,  56, 138,  54, 101]),\n",
              "  'red_bans': tensor([123, 113, 142,  53,  73]),\n",
              "  'blue_picks': tensor([ 94, 106,  50,  55, 104]),\n",
              "  'red_picks': tensor([163, 130, 147, 140,   5]),\n",
              "  'winner_token': 1,\n",
              "  'blue_roles': tensor([3, 4, 2, 5, 6]),\n",
              "  'red_roles': tensor([5, 3, 2, 4, 6])},\n",
              " {'patch': '14.5',\n",
              "  'blue_bans': tensor([106, 123,  56,  53,  19]),\n",
              "  'red_bans': tensor([  2, 142, 138,  54, 147]),\n",
              "  'blue_picks': tensor([113,  87, 130, 156,  38]),\n",
              "  'red_picks': tensor([ 94,  69, 140, 163, 101]),\n",
              "  'winner_token': 1,\n",
              "  'blue_roles': tensor([5, 6, 3, 2, 4]),\n",
              "  'red_roles': tensor([3, 2, 4, 5, 6])},\n",
              " {'patch': '14.5',\n",
              "  'blue_bans': tensor([ 10, 142,  94,  54, 135]),\n",
              "  'red_bans': tensor([147, 113,  56,  50, 130]),\n",
              "  'blue_picks': tensor([ 73, 104,  85,   1,   2]),\n",
              "  'red_picks': tensor([  9,  78,  74, 138,  23]),\n",
              "  'winner_token': 1,\n",
              "  'blue_roles': tensor([5, 2, 6, 4, 3]),\n",
              "  'red_roles': tensor([5, 2, 6, 4, 3])}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_sequence = [{\n",
        "            \"champ_name\": START_TOKEN,\n",
        "            \"champ_id\": champ_tokenizer.encode([START_TOKEN])[0],\n",
        "            \"team\": torch.tensor(0),\n",
        "            \"type\": torch.tensor(0),\n",
        "            \"position\": torch.tensor(0),\n",
        "            \"role\": torch.tensor(0),\n",
        "            \"score\": torch.tensor(0, dtype=torch.float),\n",
        "            \"class\": torch.tensor([0]),\n",
        "            \"class_name\": [\"START\"],\n",
        "            \"winner_emb\": torch.tensor(0),\n",
        "}]\n",
        "\n",
        "DRAFT_SEQUENCE = [\n",
        "    {\"team\": 1, \"type\": 1, \"index\": 0},\n",
        "    {\"team\": 2, \"type\": 1, \"index\": 0},\n",
        "    {\"team\": 1, \"type\": 1, \"index\": 1},\n",
        "    {\"team\": 2, \"type\": 1, \"index\": 1},\n",
        "    {\"team\": 1, \"type\": 1, \"index\": 2},\n",
        "    {\"team\": 2, \"type\": 1, \"index\": 2},\n",
        "    {\"team\": 1, \"type\": 2, \"index\": 0},\n",
        "    {\"team\": 2, \"type\": 2, \"index\": 0},\n",
        "    {\"team\": 2, \"type\": 2, \"index\": 1},\n",
        "    {\"team\": 1, \"type\": 2, \"index\": 1},\n",
        "    {\"team\": 1, \"type\": 2, \"index\": 2},\n",
        "    {\"team\": 2, \"type\": 2, \"index\": 2},\n",
        "    {\"team\": 2, \"type\": 1, \"index\": 3},\n",
        "    {\"team\": 1, \"type\": 1, \"index\": 3},\n",
        "    {\"team\": 2, \"type\": 1, \"index\": 4},\n",
        "    {\"team\": 1, \"type\": 1, \"index\": 4},\n",
        "    {\"team\": 2, \"type\": 2, \"index\": 3},\n",
        "    {\"team\": 1, \"type\": 2, \"index\": 3},\n",
        "    {\"team\": 1, \"type\": 2, \"index\": 4},\n",
        "    {\"team\": 2, \"type\": 2, \"index\": 4},\n",
        "]"
      ],
      "metadata": {
        "id": "Wgn71sv-pOHD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def structured_sequence(match):\n",
        "    seq = []\n",
        "    patch = match['patch']\n",
        "    patch_champion_scores = champion_scores[patch]\n",
        "\n",
        "    for pos, op in enumerate(DRAFT_SEQUENCE):\n",
        "        team = \"blue\" if op[\"team\"] == 1 else \"red\"\n",
        "        champ_ids = match[f\"{team}_{'picks' if op['type'] == 2 else 'bans'}\"]\n",
        "        roles = match[f\"{team}_roles\"]\n",
        "\n",
        "        champ_id = champ_ids[op[\"index\"]]\n",
        "        champ_name = champ_tokenizer.decode([champ_id])[0]\n",
        "\n",
        "        if op['type'] == 2:  # pick\n",
        "            role_id = roles[op[\"index\"]]\n",
        "            role = champ_tokenizer.id_to_role[role_id.item()]\n",
        "            score_csv = patch_champion_scores[\n",
        "                (patch_champion_scores['champion'] == champ_name) &\n",
        "                (patch_champion_scores['role'] == role.lower())\n",
        "            ]\n",
        "        else:\n",
        "            role = 'Banned'\n",
        "            role_id = champ_tokenizer.encodeRole([role])[0]\n",
        "            score_csv = patch_champion_scores[\n",
        "                (patch_champion_scores['champion'] == champ_name)\n",
        "            ]\n",
        "\n",
        "        class_ = class_tokenizer.encode(champ_classes[champ_name])\n",
        "        score = float(score_csv['score'].values[0]) if not score_csv.empty else 48.0\n",
        "        winner_emb = 2 if op['team'] == match['winner_token'] else 1\n",
        "        seq.append({\n",
        "            \"champ_id\": champ_id,\n",
        "            \"team\": torch.tensor(op[\"team\"]),\n",
        "            \"type\": torch.tensor(op[\"type\"]),\n",
        "            \"position\": torch.tensor(pos),\n",
        "            \"role\": role_id,\n",
        "            \"class\": class_,\n",
        "            \"score\": torch.tensor(score),\n",
        "            \"winner_emb\": torch.tensor(winner_emb),\n",
        "        })\n",
        "\n",
        "    seq = start_sequence + seq\n",
        "    return seq"
      ],
      "metadata": {
        "id": "Qm-szMBKpRVi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL DESIGNING**"
      ],
      "metadata": {
        "id": "8kzU5Fjdps0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "champion_emb = 384\n",
        "n_head = 8\n",
        "dropout = 0.2\n",
        "n_layer = 6\n",
        "\n",
        "SPECIAL_ROLE_IDX = 0  # reserved for start\n",
        "BANNED_ROLE_IDX = champ_tokenizer.encodeRole(['Banned'])[0]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "sequences = [structured_sequence(match) for match in matches]\n",
        "n = int(len(sequences) * 0.9)\n",
        "train_data = sequences[:n]\n",
        "val_data = sequences[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data), (batch_size,))\n",
        "    batch = [data[i.item()] for i in ix]\n",
        "    x = [item[:-1] for item in batch]\n",
        "    y = [item[1:] for item in batch]\n",
        "    return x, y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, emb_dim, n_head):\n",
        "        super().__init__()\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "        self.k_proj = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "        self.v_proj = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "        self.attention = nn.MultiheadAttention(emb_dim, n_head, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(emb_dim, emb_dim * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(emb_dim * 4, emb_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm1(x)\n",
        "        q = self.q_proj(x)\n",
        "        k = self.k_proj(x)\n",
        "        v = self.v_proj(x)\n",
        "        T = x.size(1)\n",
        "        attn_mask = torch.tril(torch.ones(T, T, device=x.device))\n",
        "        attn_mask = attn_mask.masked_fill(attn_mask == 0, float('-inf')).masked_fill(attn_mask == 1, float(0.0))\n",
        "        attn_output, _ = self.attention(q, k, v, attn_mask=attn_mask)\n",
        "        x = x + attn_output\n",
        "        x = self.norm2(self.ff(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiTaskLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.log_var_role = torch.nn.Parameter(torch.zeros(1))\n",
        "        self.log_var_champ = torch.nn.Parameter(torch.zeros(1))\n",
        "        self.log_var_joint = torch.nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, role_loss, champ_loss, joint_loss):\n",
        "        role_weight  = torch.exp(-self.log_var_role)\n",
        "        champ_weight = torch.exp(-self.log_var_champ)\n",
        "        joint_weight = torch.exp(-self.log_var_joint)\n",
        "\n",
        "        total_loss = (\n",
        "            role_weight * role_loss + self.log_var_role +\n",
        "            champ_weight * champ_loss + self.log_var_champ +\n",
        "            joint_weight * joint_loss + self.log_var_joint\n",
        "        )\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "class DraftModel(nn.Module):\n",
        "    def __init__(self, champion_vocab_size, team_vocab_size, type_vocab_size, class_vocab_size, winner_vocab_size, emb_dim=128):\n",
        "        super(DraftModel, self).__init__()\n",
        "        self.champion_embedding = nn.Embedding(champion_vocab_size, emb_dim)\n",
        "        self.team_embedding = nn.Embedding(team_vocab_size, emb_dim)\n",
        "        self.type_embedding = nn.Embedding(type_vocab_size, emb_dim)\n",
        "        self.position_embedding = nn.Embedding(21, emb_dim)\n",
        "        self.class_embedding = nn.Embedding(class_vocab_size, emb_dim)\n",
        "        self.role_embedding = nn.Embedding(len(ROLES), emb_dim)\n",
        "        self.joint_head = nn.Linear(emb_dim, champion_vocab_size * len(ROLES))\n",
        "        self.score_proj = nn.Linear(1, emb_dim)\n",
        "\n",
        "        #winner emb manually declared\n",
        "        self.winner_embedding = nn.Embedding(winner_vocab_size, 1)\n",
        "        self.winner_embedding.weight.data = torch.tensor([[1.0], [0.85], [1.15]])\n",
        "        self.winner_embedding.weight.requires_grad = False  # Optional: freeze weights\n",
        "\n",
        "        self.blocks = nn.Sequential(*[Block(emb_dim, n_head) for _ in range(n_layer)])\n",
        "        self.lm_head = nn.Linear(emb_dim, champion_vocab_size)\n",
        "        self.role_head = nn.Linear(emb_dim, len(ROLES))\n",
        "\n",
        "        self.multi_loss = MultiTaskLoss()\n",
        "\n",
        "    def forward(self, batch, target=None):\n",
        "        B,T = len(batch), len(batch[0])\n",
        "        champion_ids = torch.stack([\n",
        "            torch.stack([match['champ_id'] for match in b])\n",
        "            for b in batch\n",
        "        ])\n",
        "        type_ids = torch.stack([\n",
        "            torch.stack([match['type'] for match in b])\n",
        "            for b in batch\n",
        "        ])\n",
        "        team_ids = torch.stack([\n",
        "            torch.stack([match['team'] for match in b])\n",
        "            for b in batch\n",
        "        ])\n",
        "\n",
        "        class_ids = torch.stack([torch.stack([pick['class'].sum() for pick in b]) for b in batch])\n",
        "        positions = torch.arange(T, device=device).unsqueeze(0).expand(B, T)\n",
        "        score_ids = torch.stack([\n",
        "            torch.stack([match['score'] for match in b])\n",
        "            for b in batch\n",
        "        ]).unsqueeze(-1)\n",
        "\n",
        "        champ_emb = self.champion_embedding(champion_ids)     # (B, T, C)\n",
        "        team_emb = self.team_embedding(team_ids)           # (B, T, C)\n",
        "        type_emb = self.type_embedding(type_ids)           # (B, T, C)\n",
        "        class_emb = self.class_embedding(class_ids)\n",
        "        pos_emb = self.position_embedding(positions)       # (B, T, C)\n",
        "        score_proj = self.score_proj(score_ids)\n",
        "\n",
        "        role_ids = torch.stack([\n",
        "            torch.stack([match['role'] for match in b])\n",
        "            for b in batch\n",
        "        ])\n",
        "        role_emb = self.role_embedding(role_ids)\n",
        "\n",
        "        x = champ_emb + team_emb + type_emb + pos_emb + score_proj + role_emb + class_emb # (B, T, C)\n",
        "\n",
        "        x = self.blocks(x)\n",
        "        logits = self.lm_head(x)\n",
        "        role_logits = self.role_head(x)\n",
        "\n",
        "        joint_logits = self.joint_head(x)  # (B, T, C × R)\n",
        "        joint_logits = joint_logits.view(B, T, champion_vocab_size, len(ROLES))\n",
        "        if target is not None:\n",
        "            winner_ids = torch.stack([torch.stack([pick['winner_emb'] for pick in match]) for match in batch])  # [B, C]\n",
        "            winner_emb = self.winner_embedding(winner_ids).unsqueeze(-2)\n",
        "            joint_logits *= winner_emb\n",
        "            #champion\n",
        "            target = champion_ids[:, 1:].contiguous().view(-1)\n",
        "            logits = logits[:, :-1, :].contiguous().view(B * (T - 1), -1)\n",
        "            champ_loss = F.cross_entropy(logits, target)\n",
        "            #role\n",
        "            role_target = role_ids[:, 1:].contiguous().view(-1)\n",
        "            role_logits = role_logits[:, :-1, :].contiguous().view(B * (T - 1), -1)\n",
        "            role_loss = F.cross_entropy(role_logits, role_target)\n",
        "\n",
        "            joint_target = champion_ids[:, 1:] * len(ROLES) + role_ids[:, 1:]\n",
        "            joint_logits = joint_logits[:, :-1].reshape(B * (T - 1), -1)\n",
        "            joint_loss = F.cross_entropy(joint_logits, joint_target.view(-1))\n",
        "\n",
        "            total_loss = self.multi_loss(role_loss, champ_loss, joint_loss)\n",
        "        else:\n",
        "            total_loss = None\n",
        "\n",
        "        return joint_logits, total_loss\n",
        "\n",
        "\n",
        "team_vocab_size = 3 # START, Blue, Red\n",
        "type_vocab_size = 3 # START, Ban, Pick\n",
        "model = DraftModel(champion_vocab_size, 3, 3, champion_emb, winner_vocab_size)"
      ],
      "metadata": {
        "id": "FSM4r7CCpXjT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import floor\n",
        "\n",
        "class DraftPickApp:\n",
        "    def __init__(self, k=20):\n",
        "      self.k = k\n",
        "\n",
        "    def run(self, team_blue, team_red, model, patch=latest_patch):\n",
        "        picked_mask = torch.zeros(champion_vocab_size, dtype=torch.bool, device=device)\n",
        "        patch_champion_scores = champion_scores[patch]\n",
        "        # Role masks for each team\n",
        "        role_mask = torch.zeros(len(ROLES), dtype=torch.bool, device=device)\n",
        "        role_mask[SPECIAL_ROLE_IDX] = True\n",
        "        role_mask[BANNED_ROLE_IDX] = True\n",
        "        role_masks = {\n",
        "            1: role_mask.detach().clone(),\n",
        "            2: role_mask.detach().clone()\n",
        "        }\n",
        "\n",
        "        picked_mask[champ_tokenizer.encode([START_TOKEN])[0]] = True\n",
        "        game = [[start_sequence[0].copy()]]\n",
        "        teams_input_source = {\n",
        "            1: {\n",
        "                'isPlayer': team_blue == 'player',\n",
        "                'name': 'Blue'\n",
        "            },\n",
        "            2: {\n",
        "                'isPlayer': team_red == 'player',\n",
        "                'name': 'Red'\n",
        "            }\n",
        "        }\n",
        "        for pick in DRAFT_SEQUENCE:\n",
        "            team_idx = pick['team']\n",
        "            team_role_mask = role_masks[team_idx]\n",
        "            team_isPlayer = teams_input_source[team_idx]['isPlayer']\n",
        "            team_name = teams_input_source[team_idx]['name']\n",
        "            if not team_isPlayer:\n",
        "                joint_logits, _ = model(game)\n",
        "                joint_logits = joint_logits[:, -1, :, :]  # (1, C, R)\n",
        "\n",
        "                # Mask picked champions\n",
        "                joint_logits[0, picked_mask, :] = float('-inf')\n",
        "                if pick['type'] == 2:\n",
        "                    joint_logits[0, :, team_role_mask] = float('-inf')\n",
        "                else:\n",
        "                  temp_mask = torch.zeros_like(joint_logits, dtype=torch.bool)\n",
        "                  temp_mask[0, :, BANNED_ROLE_IDX] = True\n",
        "\n",
        "                  joint_logits = joint_logits.masked_fill(~temp_mask, float('-inf'))\n",
        "                  joint_logits[0, picked_mask, :] = float('-inf')\n",
        "\n",
        "                joint_probs = F.softmax(joint_logits.view(-1), dim=0)\n",
        "                topk_probs, topk_indices = torch.topk(joint_probs, self.k)\n",
        "                topk_probs = joint_probs[topk_indices]\n",
        "                topk_probs = topk_probs / topk_probs.sum()\n",
        "                prob_index = torch.multinomial(topk_probs, 1).item()\n",
        "\n",
        "                pair_ix = topk_indices[prob_index]\n",
        "                champ_ix = floor(pair_ix / len(ROLES))\n",
        "                champ_ix = torch.tensor(champ_ix, device=device)\n",
        "\n",
        "                # 🟢 Print out the AI's decision\n",
        "                champ_name = champ_tokenizer.decode([champ_ix])[0]\n",
        "                print(f\"AI {team_name} team\", end= ' ')\n",
        "                if pick['type'] == 1:\n",
        "                    print(f\"banned {champ_name}\")\n",
        "                    role_ix = champ_tokenizer.encodeRole(['Banned'])[0]\n",
        "                    role_str = \"Banned\"\n",
        "                elif pick['type'] == 2:\n",
        "                    role_ix = pair_ix % len(ROLES)\n",
        "                    role_str = champ_tokenizer.decodeRole([role_ix.item()])[0]\n",
        "                    print(f\"picked {champ_name} as {role_str}\")\n",
        "\n",
        "            else:\n",
        "                while True:\n",
        "                    champ_name = input(f'{\"BAN\" if pick[\"type\"] == 1 else \"PICK\"} a champ: ').strip()\n",
        "\n",
        "                    # Check if it's a known champ\n",
        "                    if champ_name not in champ_tokenizer.token_to_id:\n",
        "                        print(f\"'{champ_name}' is not a valid champion name. Try again.\")\n",
        "                        continue\n",
        "\n",
        "                    champ_ix = champ_tokenizer.encode([champ_name])[0]\n",
        "\n",
        "                    # Check if it's already picked or banned\n",
        "                    if picked_mask[champ_ix]:\n",
        "                        print(f\"{champ_name} has already been picked or banned. Try again.\")\n",
        "                        continue\n",
        "\n",
        "                    break  # valid input\n",
        "                # Ask for role input\n",
        "                if pick[\"type\"] == 2:\n",
        "                    while True:\n",
        "                        role_str = input(f\"What role will {champ_name} play? \").strip()\n",
        "                        if role_str in champ_tokenizer.role_to_id:\n",
        "                            role_ix = torch.tensor(champ_tokenizer.encodeRole([role_str])[0], device=device)\n",
        "                            break\n",
        "                        else:\n",
        "                            print(f\"'{role_str}' is not a valid role. Try again.\")\n",
        "                else:\n",
        "                  role_ix = champ_tokenizer.encodeRole(['Banned'])[0]\n",
        "                  role_str = \"Banned\"\n",
        "\n",
        "            # Update masks\n",
        "            picked_mask[champ_ix] = True\n",
        "            if pick['type'] == 2:\n",
        "                role_masks[team_idx][role_ix] = True\n",
        "\n",
        "            # Get class (token & str), meta score\n",
        "            class_name = None\n",
        "            class_ = None\n",
        "            score = 0.0\n",
        "\n",
        "            if pick['type'] != 0:\n",
        "                class_name = champ_classes[champ_name]\n",
        "                class_ = class_tokenizer.encode(class_name)\n",
        "                if pick['type'] == 1:\n",
        "                  score_csv = patch_champion_scores[\n",
        "                      (patch_champion_scores['champion'] == champ_name)\n",
        "                  ]\n",
        "                else:\n",
        "                  score_csv = patch_champion_scores[\n",
        "                      (patch_champion_scores['champion'] == champ_name) &\n",
        "                      (patch_champion_scores['role'] == role_str)\n",
        "                  ]\n",
        "                score = float(score_csv['score'].values[0]) if not score_csv.empty else 48.0\n",
        "\n",
        "            new_pick = {\n",
        "                \"champ_name\": champ_name,\n",
        "                \"champ_id\": champ_ix,\n",
        "                \"team\": torch.tensor(pick['team']),\n",
        "                \"type\": torch.tensor(pick['type']),\n",
        "                \"position\": torch.tensor(pick['index']),\n",
        "                \"role\": role_ix,\n",
        "                \"score\": torch.tensor(score),\n",
        "                \"class_name\": class_name,\n",
        "                \"class\": class_\n",
        "            }\n",
        "            game[0].append(new_pick)\n",
        "        return game[0]\n",
        "\n",
        "\n",
        "def print_draft(draft):\n",
        "    print(f\"{'STEP':<4} | {'ACTION':<6} | {'TEAM':<5} | {'CHAMPION':<15} | {'ROLE':<7} | {'CLASS'}\")\n",
        "    print(\"-\" * 60)\n",
        "    for i, step in enumerate(draft):\n",
        "        champ = step[\"champ_name\"]\n",
        "        team = [\"start\", \"blue\", \"red\"][step[\"team\"]]\n",
        "        action = [\"start\", \"ban\", \"pick\"][step[\"type\"]]\n",
        "        class_ = step[\"class_name\"]\n",
        "        role = champ_tokenizer.id_to_role[step[\"role\"].item()]\n",
        "        print(f\"{i:<4} | {action.upper():<6} | {team.upper():<5} | {champ:<15} | {role:<7} | {', '.join(class_)}\")\n",
        "\n",
        "draftapp = DraftPickApp()"
      ],
      "metadata": {
        "id": "JwGfL-ZHqD1z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draftapp = DraftPickApp()\n",
        "draft = draftapp.run('ai', 'ai', model)\n",
        "print_draft(draft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcsRFpzmwB-3",
        "outputId": "66bd7995-c4da-4283-f9ed-398faf3aa096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Blue team banned Maokai\n",
            "AI Red team banned Corki\n",
            "AI Blue team banned Kalista\n",
            "AI Red team banned Lucian\n",
            "AI Blue team banned Sejuani\n",
            "AI Red team banned Senna\n",
            "AI Blue team picked Vi as Jungle\n",
            "AI Red team picked Udyr as Top\n",
            "AI Red team picked Rakan as Support\n",
            "AI Blue team picked Milio as Support\n",
            "AI Blue team picked Varus as Bot\n",
            "AI Red team picked Karma as Mid\n",
            "AI Red team banned Smolder\n",
            "AI Blue team banned K'Sante\n",
            "AI Red team banned Orianna\n",
            "AI Blue team banned Ashe\n",
            "AI Red team picked Poppy as Jungle\n",
            "AI Blue team picked Gnar as Top\n",
            "AI Blue team picked Azir as Mid\n",
            "AI Red team picked Aphelios as Bot\n",
            "STEP | ACTION | TEAM  | CHAMPION        | ROLE    | CLASS\n",
            "------------------------------------------------------------\n",
            "0    | START  | START | <start>         | Start   | START\n",
            "1    | BAN    | BLUE  | Maokai          | Banned  | Vanguard\n",
            "2    | BAN    | RED   | Corki           | Banned  | Marksman\n",
            "3    | BAN    | BLUE  | Kalista         | Banned  | Marksman\n",
            "4    | BAN    | RED   | Lucian          | Banned  | Marksman\n",
            "5    | BAN    | BLUE  | Sejuani         | Banned  | Vanguard\n",
            "6    | BAN    | RED   | Senna           | Banned  | Marksman, Enchanter\n",
            "7    | PICK   | BLUE  | Vi              | Jungle  | Diver\n",
            "8    | PICK   | RED   | Udyr            | Top     | Juggernaut\n",
            "9    | PICK   | RED   | Rakan           | Support | Catcher\n",
            "10   | PICK   | BLUE  | Milio           | Support | Enchanter\n",
            "11   | PICK   | BLUE  | Varus           | Bot     | Marksman, Artillery\n",
            "12   | PICK   | RED   | Karma           | Mid     | Burst, Enchanter\n",
            "13   | BAN    | RED   | Smolder         | Banned  | Marksman\n",
            "14   | BAN    | BLUE  | K'Sante         | Banned  | Warden, Skirmisher\n",
            "15   | BAN    | RED   | Orianna         | Banned  | Burst\n",
            "16   | BAN    | BLUE  | Ashe            | Banned  | Marksman\n",
            "17   | PICK   | RED   | Poppy           | Jungle  | Warden\n",
            "18   | PICK   | BLUE  | Gnar            | Top     | Specialist\n",
            "19   | PICK   | BLUE  | Azir            | Mid     | Specialist\n",
            "20   | PICK   | RED   | Aphelios        | Bot     | Marksman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL TRAINING**"
      ],
      "metadata": {
        "id": "d-Pzf9RnxJWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "max_steps = 5000\n",
        "lossi = []\n",
        "for i in range(max_steps):\n",
        "    model.train()\n",
        "    x, y = get_batch('train')\n",
        "    _, loss = model(x, y)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f\"Step {i}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    lossi.append(loss.item())\n",
        "\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1I_pfYAwij3",
        "outputId": "bd5f113e-93bd-4d73-a759-f11011924f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 14.8308\n",
            "Step 50, Loss: 9.7087\n",
            "Step 100, Loss: 9.1091\n",
            "Step 150, Loss: 8.5682\n",
            "Step 200, Loss: 8.3928\n",
            "Step 250, Loss: 7.6148\n",
            "Step 300, Loss: 7.3861\n",
            "Step 350, Loss: 8.7897\n",
            "Step 400, Loss: 8.3945\n",
            "Step 450, Loss: 7.9653\n",
            "Step 500, Loss: 7.8628\n",
            "Step 550, Loss: 7.6431\n",
            "Step 600, Loss: 7.6302\n",
            "Step 650, Loss: 7.4903\n",
            "Step 700, Loss: 7.4520\n",
            "Step 750, Loss: 7.3163\n",
            "Step 800, Loss: 7.2012\n",
            "Step 850, Loss: 7.0783\n",
            "Step 900, Loss: 6.9986\n",
            "Step 950, Loss: 6.9808\n",
            "Step 1000, Loss: 6.9161\n",
            "Step 1050, Loss: 6.8073\n",
            "Step 1100, Loss: 6.7682\n",
            "Step 1150, Loss: 6.7444\n",
            "Step 1200, Loss: 6.7231\n",
            "Step 1250, Loss: 6.6744\n",
            "Step 1300, Loss: 6.5920\n",
            "Step 1350, Loss: 6.5602\n",
            "Step 1400, Loss: 6.4685\n",
            "Step 1450, Loss: 6.4553\n",
            "Step 1500, Loss: 6.4100\n",
            "Step 1550, Loss: 6.3912\n",
            "Step 1600, Loss: 6.4182\n",
            "Step 1650, Loss: 6.3700\n",
            "Step 1700, Loss: 6.3361\n",
            "Step 1750, Loss: 6.2789\n",
            "Step 1800, Loss: 6.2414\n",
            "Step 1850, Loss: 6.3663\n",
            "Step 1900, Loss: 6.2136\n",
            "Step 1950, Loss: 6.2084\n",
            "Step 2000, Loss: 6.1665\n",
            "Step 2050, Loss: 6.1790\n",
            "Step 2100, Loss: 6.2569\n",
            "Step 2150, Loss: 6.2090\n",
            "Step 2200, Loss: 6.1595\n",
            "Step 2250, Loss: 6.1389\n",
            "Step 2300, Loss: 6.1536\n",
            "Step 2350, Loss: 6.1499\n",
            "Step 2400, Loss: 6.2710\n",
            "Step 2450, Loss: 6.1247\n",
            "Step 2500, Loss: 6.1033\n",
            "Step 2550, Loss: 6.1235\n",
            "Step 2600, Loss: 6.1498\n",
            "Step 2650, Loss: 6.1131\n",
            "Step 2700, Loss: 6.1152\n",
            "Step 2750, Loss: 6.1630\n",
            "Step 2800, Loss: 6.0251\n",
            "Step 2850, Loss: 6.0695\n",
            "Step 2900, Loss: 6.0596\n",
            "Step 2950, Loss: 6.0730\n",
            "Step 3000, Loss: 6.0508\n",
            "Step 3050, Loss: 5.9910\n",
            "Step 3100, Loss: 5.9834\n",
            "Step 3150, Loss: 5.9739\n",
            "Step 3200, Loss: 6.0357\n",
            "Step 3250, Loss: 6.1201\n",
            "Step 3300, Loss: 6.0515\n",
            "Step 3350, Loss: 6.0283\n",
            "Step 3400, Loss: 6.0050\n",
            "Step 3450, Loss: 6.0573\n",
            "Step 3500, Loss: 6.0161\n",
            "Step 3550, Loss: 6.0281\n",
            "Step 3600, Loss: 6.0233\n",
            "Step 3650, Loss: 5.9735\n",
            "Step 3700, Loss: 6.0901\n",
            "Step 3750, Loss: 5.9876\n",
            "Step 3800, Loss: 6.0160\n",
            "Step 3850, Loss: 6.0308\n",
            "Step 3900, Loss: 5.9662\n",
            "Step 3950, Loss: 6.0106\n",
            "Step 4000, Loss: 5.9991\n",
            "Step 4050, Loss: 6.0634\n",
            "Step 4100, Loss: 5.9382\n",
            "Step 4150, Loss: 5.9241\n",
            "Step 4200, Loss: 5.9910\n",
            "Step 4250, Loss: 5.9277\n",
            "Step 4300, Loss: 6.0843\n",
            "Step 4350, Loss: 6.0221\n",
            "Step 4400, Loss: 5.9780\n",
            "Step 4450, Loss: 5.9158\n",
            "Step 4500, Loss: 5.9627\n",
            "Step 4550, Loss: 6.0239\n",
            "Step 4600, Loss: 5.9887\n",
            "Step 4650, Loss: 6.0187\n",
            "Step 4700, Loss: 5.8996\n",
            "Step 4750, Loss: 6.0099\n",
            "Step 4800, Loss: 5.9567\n",
            "Step 4850, Loss: 5.9144\n",
            "Step 4900, Loss: 5.9066\n",
            "Step 4950, Loss: 5.8796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lossi = torch.tensor(lossi)\n",
        "loss_50 = lossi.view(-1, 50)\n",
        "loss_50_mean = loss_50.mean(dim=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss_50_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "eNl9pNCKxNjo",
        "outputId": "db0c8ab7-f1f5-4bce-d6d2-3267f254b7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-64-3327611419.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  lossi = torch.tensor(lossi)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79f204188290>]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()  # switch to evaluation mode if you're not training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m60WM-mg2XEa",
        "outputId": "1a43318d-2595-4885-8adb-aa1571741050"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DraftModel(\n",
              "  (champion_embedding): Embedding(168, 128)\n",
              "  (team_embedding): Embedding(3, 128)\n",
              "  (type_embedding): Embedding(3, 128)\n",
              "  (position_embedding): Embedding(21, 128)\n",
              "  (class_embedding): Embedding(384, 128)\n",
              "  (role_embedding): Embedding(7, 128)\n",
              "  (joint_head): Linear(in_features=128, out_features=1176, bias=True)\n",
              "  (score_proj): Linear(in_features=1, out_features=128, bias=True)\n",
              "  (winner_embedding): Embedding(3, 1)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Block(\n",
              "      (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (2): Block(\n",
              "      (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (3): Block(\n",
              "      (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (4): Block(\n",
              "      (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (5): Block(\n",
              "      (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=128, out_features=168, bias=True)\n",
              "  (role_head): Linear(in_features=128, out_features=7, bias=True)\n",
              "  (multi_loss): MultiTaskLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draft = draftapp.run('ai', 'ai', model)\n",
        "print_draft(draft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jn30UmL12P1",
        "outputId": "321e35ca-7262-4667-d7f9-3adbdd700b43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Blue team banned Ashe\n",
            "AI Red team banned Maokai\n",
            "AI Blue team banned Kalista\n",
            "AI Red team banned Orianna\n",
            "AI Blue team banned Lee Sin\n",
            "AI Red team banned Vi\n",
            "AI Blue team picked Varus as Bot\n",
            "AI Red team picked K'Sante as Top\n",
            "AI Red team picked Corki as Mid\n",
            "AI Blue team picked Sejuani as Jungle\n",
            "AI Blue team picked Senna as Support\n",
            "AI Red team picked Smolder as Bot\n",
            "AI Red team banned Udyr\n",
            "AI Blue team banned Poppy\n",
            "AI Red team banned Rakan\n",
            "AI Blue team banned Azir\n",
            "AI Red team picked Milio as Support\n",
            "AI Blue team picked Rumble as Top\n",
            "AI Blue team picked Tristana as Mid\n",
            "AI Red team picked Xin Zhao as Jungle\n",
            "STEP | ACTION | TEAM  | CHAMPION        | ROLE    | CLASS\n",
            "------------------------------------------------------------\n",
            "0    | START  | START | <start>         | Start   | START\n",
            "1    | BAN    | BLUE  | Ashe            | Banned  | Marksman\n",
            "2    | BAN    | RED   | Maokai          | Banned  | Vanguard\n",
            "3    | BAN    | BLUE  | Kalista         | Banned  | Marksman\n",
            "4    | BAN    | RED   | Orianna         | Banned  | Burst\n",
            "5    | BAN    | BLUE  | Lee Sin         | Banned  | Diver\n",
            "6    | BAN    | RED   | Vi              | Banned  | Diver\n",
            "7    | PICK   | BLUE  | Varus           | Bot     | Marksman, Artillery\n",
            "8    | PICK   | RED   | K'Sante         | Top     | Warden, Skirmisher\n",
            "9    | PICK   | RED   | Corki           | Mid     | Marksman\n",
            "10   | PICK   | BLUE  | Sejuani         | Jungle  | Vanguard\n",
            "11   | PICK   | BLUE  | Senna           | Support | Marksman, Enchanter\n",
            "12   | PICK   | RED   | Smolder         | Bot     | Marksman\n",
            "13   | BAN    | RED   | Udyr            | Banned  | Juggernaut\n",
            "14   | BAN    | BLUE  | Poppy           | Banned  | Warden\n",
            "15   | BAN    | RED   | Rakan           | Banned  | Catcher\n",
            "16   | BAN    | BLUE  | Azir            | Banned  | Specialist\n",
            "17   | PICK   | RED   | Milio           | Support | Enchanter\n",
            "18   | PICK   | BLUE  | Rumble          | Top     | Battlemage\n",
            "19   | PICK   | BLUE  | Tristana        | Mid     | Marksman\n",
            "20   | PICK   | RED   | Xin Zhao        | Jungle  | Diver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draft = draftapp.run('player', 'ai', model)\n",
        "print_draft(draft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLsZl30j2FDK",
        "outputId": "65231705-a4d1-4f36-b922-3aff3bfe478a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BAN a champ: Azir\n",
            "AI Red team banned Corki\n",
            "BAN a champ: Annie\n",
            "AI Red team banned Poppy\n",
            "BAN a champ: Vi\n",
            "AI Red team banned Senna\n",
            "PICK a champ: Rumble\n",
            "What role will Rumble play? Top\n",
            "AI Red team picked Ashe as Support\n",
            "AI Red team picked K'Sante as Top\n",
            "PICK a champ: Vi\n",
            "Vi has already been picked or banned. Try again.\n",
            "PICK a champ: Jarvan IV\n",
            "What role will Jarvan IV play? Jungle\n",
            "PICK a champ: Kalista\n",
            "What role will Kalista play? Bot\n",
            "AI Red team picked Orianna as Mid\n",
            "AI Red team banned Smolder\n",
            "BAN a champ: Caitlyn\n",
            "AI Red team banned Ahri\n",
            "BAN a champ: Karma\n",
            "AI Red team picked Varus as Bot\n",
            "PICK a champ: Renata Glasc\n",
            "What role will Renata Glasc play? Support\n",
            "PICK a champ: Taliyah\n",
            "What role will Taliyah play? Mid\n",
            "AI Red team picked Lee Sin as Jungle\n",
            "STEP | ACTION | TEAM  | CHAMPION        | ROLE    | CLASS\n",
            "------------------------------------------------------------\n",
            "0    | START  | START | <start>         | Start   | START\n",
            "1    | BAN    | BLUE  | Azir            | Banned  | Specialist\n",
            "2    | BAN    | RED   | Corki           | Banned  | Marksman\n",
            "3    | BAN    | BLUE  | Annie           | Banned  | Burst\n",
            "4    | BAN    | RED   | Poppy           | Banned  | Warden\n",
            "5    | BAN    | BLUE  | Vi              | Banned  | Diver\n",
            "6    | BAN    | RED   | Senna           | Banned  | Marksman, Enchanter\n",
            "7    | PICK   | BLUE  | Rumble          | Top     | Battlemage\n",
            "8    | PICK   | RED   | Ashe            | Support | Marksman\n",
            "9    | PICK   | RED   | K'Sante         | Top     | Warden, Skirmisher\n",
            "10   | PICK   | BLUE  | Jarvan IV       | Jungle  | Diver\n",
            "11   | PICK   | BLUE  | Kalista         | Bot     | Marksman\n",
            "12   | PICK   | RED   | Orianna         | Mid     | Burst\n",
            "13   | BAN    | RED   | Smolder         | Banned  | Marksman\n",
            "14   | BAN    | BLUE  | Caitlyn         | Banned  | Marksman\n",
            "15   | BAN    | RED   | Ahri            | Banned  | Burst\n",
            "16   | BAN    | BLUE  | Karma           | Banned  | Burst, Enchanter\n",
            "17   | PICK   | RED   | Varus           | Bot     | Marksman, Artillery\n",
            "18   | PICK   | BLUE  | Renata Glasc    | Support | Enchanter\n",
            "19   | PICK   | BLUE  | Taliyah         | Mid     | Battlemage\n",
            "20   | PICK   | RED   | Lee Sin         | Jungle  | Diver\n"
          ]
        }
      ]
    }
  ]
}